{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import h5py\n",
    "\n",
    "from PIL import Image\n",
    "from pyts.image import RecurrencePlot, GramianAngularField\n",
    "from pyts.datasets import load_gunpoint\n",
    "from pyts.image import MarkovTransitionField\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Conv3D,Conv2D, MaxPooling3D, MaxPooling2D, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make GAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 1\n",
    "\n",
    "path = 'E:/Data/new_EEG/7680/'\n",
    "save_path = 'E:/Data/new_EEG/vgg_data_GAF/7680/data/'\n",
    "file_list = os.listdir('input')\n",
    "\n",
    "for file in file_list:\n",
    "    #if os.path.isfile(save_path+file):\n",
    "    #    continue\n",
    "        \n",
    "    start = time.time()\n",
    "    \n",
    "    data = pd.read_csv('input/'+file, header=0)\n",
    "    rp = GramianAngularField(image_size=224, method='d')\n",
    "    data_rp = rp.fit_transform(data.T)\n",
    "    #input_data=(make_input_size(data_rp))# / 255.0)\n",
    "    \n",
    "    np.savez_compressed(save_path+file[:-4], data_rp)\n",
    "    \n",
    "    print(\"%d time : \"%check, time.time() - start)\n",
    "    check  = check+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check = 1\n",
    "\n",
    "path = 'E:/Data/new_EEG/1280/'\n",
    "save_path = 'E:/Data/new_EEG/vgg_data_GAF/1280/data/'\n",
    "file_list = os.listdir('input_split_6')\n",
    "\n",
    "for file in file_list:\n",
    "    #if os.path.isfile(save_path+file):\n",
    "    #    continue\n",
    "        \n",
    "    start = time.time()\n",
    "    \n",
    "    data = pd.read_csv('input_split_6/'+file, header=0)\n",
    "    rp = GramianAngularField(image_size=224, method='d')\n",
    "    data_rp = rp.fit_transform(data.T)\n",
    "    #input_data=(make_input_size(data_rp))# / 255.0)\n",
    "    \n",
    "    np.savez_compressed(save_path+file[:-4], data_rp)\n",
    "    \n",
    "    print(\"%d time : \"%check, time.time() - start)\n",
    "    check  = check+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check = 1\n",
    "\n",
    "path = 'E:/Data/new_EEG/640/'\n",
    "save_path = 'E:/Data/new_EEG/vgg_data_GAF/640/data/'\n",
    "file_list = os.listdir('input_split_12')\n",
    "\n",
    "for file in file_list:\n",
    "    #if os.path.isfile(save_path+file):\n",
    "    #    continue\n",
    "        \n",
    "    start = time.time()\n",
    "    \n",
    "    data = pd.read_csv('input_split_12/'+file, header=0)\n",
    "    rp = GramianAngularField(image_size=224, method='d')\n",
    "    data_rp = rp.fit_transform(data.T)\n",
    "    #input_data=(make_input_size(data_rp))# / 255.0)\n",
    "    \n",
    "    np.savez_compressed(save_path+file[:-4], data_rp)\n",
    "    \n",
    "    print(\"%d time : \"%check, time.time() - start)\n",
    "    check  = check+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_size(data):\n",
    "    #data = data*255\n",
    "    img = Image.fromarray(data[0].astype('uint8'), 'L')\n",
    "    img = img.resize((224,224))\n",
    "    img_arr = np.asarray(img)\n",
    "    result_arr = img_arr\n",
    "    \n",
    "    for i in range(1,16):\n",
    "        img = Image.fromarray(data[i].astype('uint8'), 'L')\n",
    "        img = img.resize((224,224))\n",
    "        img_arr = np.asarray(img)\n",
    "        result_arr = np.concatenate([result_arr, img_arr], axis=0)\n",
    "    \n",
    "    result_arr = result_arr.reshape(-1,224,224)\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Curve\n",
    "\n",
    "def draw_plot(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    pre_trained_vgg.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     #kernel_regularizer=regularizers.l2(0.01),\n",
    "                     #data_format = 'channels_first',\n",
    "                     input_shape=(224,224,1)))\n",
    "    model.add(pre_trained_vgg)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "    \n",
    "    #return model\n",
    "    return model, model.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Input Data & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Data/new_EEG/vgg_data_GAF/7680/data/'\n",
    "x_data = []\n",
    "y_data = []\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "for file in file_list:\n",
    "    if file[:3] == 'sch':\n",
    "        for a in range(16):\n",
    "            y_data.append(1)\n",
    "    else:\n",
    "        for a in range(16):\n",
    "            y_data.append(0)\n",
    "        \n",
    "    data = np.load(path+file)\n",
    "    data = data['arr_0']\n",
    "    x_data.append(data)\n",
    "        \n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "x_data = x_data.reshape(-1,224,224, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'E:/Data/new_EEG/vgg_data_GAF/7680/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(same_old_model, first_weights):\n",
    "    same_old_model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_mat(test):\n",
    "    y_pred = model.predict_classes(x_data[test])\n",
    "    return confusion_matrix(y_data[test], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=50, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "---------------------------epoch :  1 ---------------------------\n",
      "Epoch 1/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.9794 - accuracy: 0.5170\n",
      "Epoch 2/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.8640 - accuracy: 0.5591\n",
      "Epoch 3/200\n",
      "1209/1209 [==============================] - 19s 15ms/step - loss: 0.7648 - accuracy: 0.5583\n",
      "Epoch 4/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.7030 - accuracy: 0.5922\n",
      "Epoch 5/200\n",
      "1209/1209 [==============================] - 30s 25ms/step - loss: 0.6525 - accuracy: 0.6294\n",
      "Epoch 6/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.6472 - accuracy: 0.6294\n",
      "Epoch 7/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.6293 - accuracy: 0.6518\n",
      "Epoch 8/200\n",
      "1209/1209 [==============================] - 19s 15ms/step - loss: 0.5846 - accuracy: 0.6799\n",
      "Epoch 9/200\n",
      "1209/1209 [==============================] - 19s 15ms/step - loss: 0.5859 - accuracy: 0.6890\n",
      "Epoch 10/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.5446 - accuracy: 0.7270\n",
      "Epoch 11/200\n",
      "1209/1209 [==============================] - 22s 19ms/step - loss: 0.5201 - accuracy: 0.7452\n",
      "Epoch 12/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.4902 - accuracy: 0.7676\n",
      "Epoch 13/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.4898 - accuracy: 0.7610\n",
      "Epoch 14/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.4888 - accuracy: 0.7502\n",
      "Epoch 15/200\n",
      "1209/1209 [==============================] - 25s 20ms/step - loss: 0.4504 - accuracy: 0.7758\n",
      "Epoch 16/200\n",
      "1209/1209 [==============================] - 14s 11ms/step - loss: 0.4387 - accuracy: 0.7940\n",
      "Epoch 17/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.4376 - accuracy: 0.7965\n",
      "Epoch 18/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.4153 - accuracy: 0.8065\n",
      "Epoch 19/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.4273 - accuracy: 0.8031\n",
      "Epoch 20/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.3861 - accuracy: 0.8147\n",
      "Epoch 21/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.3781 - accuracy: 0.8321\n",
      "Epoch 22/200\n",
      "1209/1209 [==============================] - 26s 21ms/step - loss: 0.3833 - accuracy: 0.8304\n",
      "Epoch 23/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.3707 - accuracy: 0.8346\n",
      "Epoch 24/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.3226 - accuracy: 0.8594\n",
      "Epoch 25/200\n",
      "1209/1209 [==============================] - 21s 18ms/step - loss: 0.3583 - accuracy: 0.8371\n",
      "Epoch 26/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.3168 - accuracy: 0.8660\n",
      "Epoch 27/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.3271 - accuracy: 0.8528\n",
      "Epoch 28/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.3403 - accuracy: 0.8486\n",
      "Epoch 29/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.3372 - accuracy: 0.8453\n",
      "Epoch 30/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.3167 - accuracy: 0.8685\n",
      "Epoch 31/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.2829 - accuracy: 0.8759\n",
      "Epoch 32/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.3292 - accuracy: 0.8602\n",
      "Epoch 33/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.2873 - accuracy: 0.8718\n",
      "Epoch 34/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.2456 - accuracy: 0.9041\n",
      "Epoch 35/200\n",
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.2809 - accuracy: 0.87845s - los\n",
      "Epoch 36/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.2856 - accuracy: 0.8809\n",
      "Epoch 37/200\n",
      "1209/1209 [==============================] - 26s 22ms/step - loss: 0.2708 - accuracy: 0.8842\n",
      "Epoch 38/200\n",
      "1209/1209 [==============================] - 26s 22ms/step - loss: 0.2406 - accuracy: 0.8983\n",
      "Epoch 39/200\n",
      "1209/1209 [==============================] - 21s 18ms/step - loss: 0.2612 - accuracy: 0.8784\n",
      "Epoch 40/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.2574 - accuracy: 0.8925\n",
      "Epoch 41/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.2491 - accuracy: 0.8883\n",
      "Epoch 42/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.2734 - accuracy: 0.8759\n",
      "Epoch 43/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.2603 - accuracy: 0.8908\n",
      "Epoch 44/200\n",
      "1209/1209 [==============================] - 21s 18ms/step - loss: 0.2500 - accuracy: 0.8892\n",
      "Epoch 45/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.2553 - accuracy: 0.8892\n",
      "Epoch 46/200\n",
      "1209/1209 [==============================] - 27s 23ms/step - loss: 0.2675 - accuracy: 0.8792\n",
      "Epoch 47/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.2698 - accuracy: 0.8759\n",
      "Epoch 48/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.2627 - accuracy: 0.8834\n",
      "Epoch 49/200\n",
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.2360 - accuracy: 0.8916\n",
      "Epoch 50/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.2160 - accuracy: 0.9123\n",
      "Epoch 51/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.2140 - accuracy: 0.9132\n",
      "Epoch 52/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.2183 - accuracy: 0.8966\n",
      "Epoch 53/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.2192 - accuracy: 0.8983\n",
      "Epoch 54/200\n",
      "1209/1209 [==============================] - 28s 23ms/step - loss: 0.2193 - accuracy: 0.9041\n",
      "Epoch 55/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.2206 - accuracy: 0.9074\n",
      "Epoch 56/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1818 - accuracy: 0.9239\n",
      "Epoch 57/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.2194 - accuracy: 0.9057\n",
      "Epoch 58/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.2203 - accuracy: 0.8983\n",
      "Epoch 59/200\n",
      "1209/1209 [==============================] - 27s 22ms/step - loss: 0.2336 - accuracy: 0.8974\n",
      "Epoch 60/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.2245 - accuracy: 0.9024\n",
      "Epoch 61/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.2466 - accuracy: 0.8859\n",
      "Epoch 62/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.2553 - accuracy: 0.8751\n",
      "Epoch 63/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.2702 - accuracy: 0.8701\n",
      "Epoch 64/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.2293 - accuracy: 0.8958\n",
      "Epoch 65/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.2353 - accuracy: 0.8850\n",
      "Epoch 66/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.2710 - accuracy: 0.8710\n",
      "Epoch 67/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.2242 - accuracy: 0.9049\n",
      "Epoch 68/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.2459 - accuracy: 0.8900\n",
      "Epoch 69/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.2147 - accuracy: 0.9074\n",
      "Epoch 70/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.2162 - accuracy: 0.9057\n",
      "Epoch 71/200\n",
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.2268 - accuracy: 0.8958\n",
      "Epoch 72/200\n",
      "1209/1209 [==============================] - 27s 23ms/step - loss: 0.2369 - accuracy: 0.8908\n",
      "Epoch 73/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.2034 - accuracy: 0.8999\n",
      "Epoch 74/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.1859 - accuracy: 0.9123\n",
      "Epoch 75/200\n",
      "1209/1209 [==============================] - 21s 18ms/step - loss: 0.1671 - accuracy: 0.9222\n",
      "Epoch 76/200\n",
      "1209/1209 [==============================] - 21s 18ms/step - loss: 0.2277 - accuracy: 0.8925\n",
      "Epoch 77/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.2065 - accuracy: 0.9007\n",
      "Epoch 78/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.2116 - accuracy: 0.8999\n",
      "Epoch 79/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.1743 - accuracy: 0.9330\n",
      "Epoch 80/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.1746 - accuracy: 0.9256\n",
      "Epoch 81/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.1752 - accuracy: 0.9313\n",
      "Epoch 82/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1537 - accuracy: 0.9363\n",
      "Epoch 83/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1879 - accuracy: 0.9074\n",
      "Epoch 84/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.2117 - accuracy: 0.9090\n",
      "Epoch 85/200\n",
      "1209/1209 [==============================] - 28s 23ms/step - loss: 0.1807 - accuracy: 0.9140\n",
      "Epoch 86/200\n",
      "1209/1209 [==============================] - 29s 24ms/step - loss: 0.1791 - accuracy: 0.9264\n",
      "Epoch 87/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.2065 - accuracy: 0.8999\n",
      "Epoch 88/200\n",
      "1209/1209 [==============================] - 27s 23ms/step - loss: 0.2069 - accuracy: 0.9024\n",
      "Epoch 89/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.2242 - accuracy: 0.9024\n",
      "Epoch 90/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.2121 - accuracy: 0.9057\n",
      "Epoch 91/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1987 - accuracy: 0.9123\n",
      "Epoch 92/200\n",
      "1209/1209 [==============================] - 19s 15ms/step - loss: 0.1721 - accuracy: 0.9264\n",
      "Epoch 93/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.1618 - accuracy: 0.9289\n",
      "Epoch 94/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1584 - accuracy: 0.9297\n",
      "Epoch 95/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.1779 - accuracy: 0.9189\n",
      "Epoch 96/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.2062 - accuracy: 0.9049\n",
      "Epoch 97/200\n",
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.1980 - accuracy: 0.9057\n",
      "Epoch 98/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.2005 - accuracy: 0.9098\n",
      "Epoch 99/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1930 - accuracy: 0.9132\n",
      "Epoch 100/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.1803 - accuracy: 0.9148\n",
      "Epoch 101/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1711 - accuracy: 0.9181\n",
      "Epoch 102/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.2158 - accuracy: 0.9115\n",
      "Epoch 103/200\n",
      "1209/1209 [==============================] - 16s 14ms/step - loss: 0.2247 - accuracy: 0.9065\n",
      "Epoch 104/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1822 - accuracy: 0.9272\n",
      "Epoch 105/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1787 - accuracy: 0.9189\n",
      "Epoch 106/200\n",
      "1209/1209 [==============================] - 19s 15ms/step - loss: 0.1827 - accuracy: 0.9148\n",
      "Epoch 107/200\n",
      "1209/1209 [==============================] - 27s 22ms/step - loss: 0.1741 - accuracy: 0.9214\n",
      "Epoch 108/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.2026 - accuracy: 0.9107\n",
      "Epoch 109/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.2133 - accuracy: 0.9007\n",
      "Epoch 110/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.1959 - accuracy: 0.9074\n",
      "Epoch 111/200\n",
      "1209/1209 [==============================] - 14s 11ms/step - loss: 0.1798 - accuracy: 0.9214\n",
      "Epoch 112/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.1594 - accuracy: 0.9289\n",
      "Epoch 113/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1850 - accuracy: 0.9140\n",
      "Epoch 114/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1809 - accuracy: 0.9222\n",
      "Epoch 115/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.1733 - accuracy: 0.9206\n",
      "Epoch 116/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.1672 - accuracy: 0.9173\n",
      "Epoch 117/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.1882 - accuracy: 0.8983\n",
      "Epoch 118/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1895 - accuracy: 0.9115\n",
      "Epoch 119/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.1875 - accuracy: 0.9107\n",
      "Epoch 120/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1645 - accuracy: 0.9181\n",
      "Epoch 121/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.1402 - accuracy: 0.9338\n",
      "Epoch 122/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.1567 - accuracy: 0.9206\n",
      "Epoch 123/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1774 - accuracy: 0.9173\n",
      "Epoch 124/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.1459 - accuracy: 0.9421\n",
      "Epoch 125/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1874 - accuracy: 0.9165\n",
      "Epoch 126/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.1965 - accuracy: 0.9189\n",
      "Epoch 127/200\n",
      "1209/1209 [==============================] - 19s 15ms/step - loss: 0.1760 - accuracy: 0.9214\n",
      "Epoch 128/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1732 - accuracy: 0.9239\n",
      "Epoch 129/200\n",
      "1209/1209 [==============================] - 21s 18ms/step - loss: 0.1729 - accuracy: 0.9214\n",
      "Epoch 130/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1802 - accuracy: 0.9132\n",
      "Epoch 131/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.1589 - accuracy: 0.9280\n",
      "Epoch 132/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1376 - accuracy: 0.9396\n",
      "Epoch 133/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.1792 - accuracy: 0.9264\n",
      "Epoch 134/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1565 - accuracy: 0.9165\n",
      "Epoch 135/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.2227 - accuracy: 0.9074\n",
      "Epoch 136/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.2226 - accuracy: 0.9049\n",
      "Epoch 137/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.2033 - accuracy: 0.9065\n",
      "Epoch 138/200\n",
      "1209/1209 [==============================] - 24s 20ms/step - loss: 0.1989 - accuracy: 0.9016\n",
      "Epoch 139/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.1981 - accuracy: 0.9090\n",
      "Epoch 140/200\n",
      "1209/1209 [==============================] - 27s 22ms/step - loss: 0.1969 - accuracy: 0.8966\n",
      "Epoch 141/200\n",
      "1209/1209 [==============================] - 27s 23ms/step - loss: 0.2372 - accuracy: 0.8859\n",
      "Epoch 142/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1909 - accuracy: 0.8974\n",
      "Epoch 143/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1820 - accuracy: 0.8991\n",
      "Epoch 144/200\n",
      "1209/1209 [==============================] - 28s 23ms/step - loss: 0.1854 - accuracy: 0.89990s - loss: 0.1840 - accuracy: 0.\n",
      "Epoch 145/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1580 - accuracy: 0.9380\n",
      "Epoch 146/200\n",
      "1209/1209 [==============================] - 18s 14ms/step - loss: 0.1577 - accuracy: 0.9256\n",
      "Epoch 147/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.1508 - accuracy: 0.9189\n",
      "Epoch 148/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.1798 - accuracy: 0.9082\n",
      "Epoch 149/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.1564 - accuracy: 0.9239\n",
      "Epoch 150/200\n",
      "1209/1209 [==============================] - 26s 22ms/step - loss: 0.1466 - accuracy: 0.9280\n",
      "Epoch 151/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1468 - accuracy: 0.9297\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.1698 - accuracy: 0.9206\n",
      "Epoch 153/200\n",
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.1377 - accuracy: 0.9305\n",
      "Epoch 154/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1283 - accuracy: 0.9404\n",
      "Epoch 155/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.1575 - accuracy: 0.9239\n",
      "Epoch 156/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.1535 - accuracy: 0.9256\n",
      "Epoch 157/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1253 - accuracy: 0.9454\n",
      "Epoch 158/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1388 - accuracy: 0.9413\n",
      "Epoch 159/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.1699 - accuracy: 0.9156\n",
      "Epoch 160/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.1607 - accuracy: 0.9313\n",
      "Epoch 161/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1475 - accuracy: 0.9380\n",
      "Epoch 162/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.1702 - accuracy: 0.9214\n",
      "Epoch 163/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1712 - accuracy: 0.9181\n",
      "Epoch 164/200\n",
      "1209/1209 [==============================] - 28s 24ms/step - loss: 0.1377 - accuracy: 0.9330\n",
      "Epoch 165/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.1838 - accuracy: 0.9049\n",
      "Epoch 166/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.1948 - accuracy: 0.9148\n",
      "Epoch 167/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1788 - accuracy: 0.9173\n",
      "Epoch 168/200\n",
      "1209/1209 [==============================] - 14s 11ms/step - loss: 0.1465 - accuracy: 0.9264\n",
      "Epoch 169/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.1809 - accuracy: 0.9057\n",
      "Epoch 170/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1578 - accuracy: 0.9247\n",
      "Epoch 171/200\n",
      "1209/1209 [==============================] - 21s 17ms/step - loss: 0.1348 - accuracy: 0.9388\n",
      "Epoch 172/200\n",
      "1209/1209 [==============================] - 23s 19ms/step - loss: 0.1517 - accuracy: 0.9214\n",
      "Epoch 173/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1744 - accuracy: 0.9181\n",
      "Epoch 174/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1471 - accuracy: 0.9347\n",
      "Epoch 175/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.1229 - accuracy: 0.9487\n",
      "Epoch 176/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1604 - accuracy: 0.9264\n",
      "Epoch 177/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1176 - accuracy: 0.9429\n",
      "Epoch 178/200\n",
      "1209/1209 [==============================] - 27s 22ms/step - loss: 0.1201 - accuracy: 0.9404\n",
      "Epoch 179/200\n",
      "1209/1209 [==============================] - 28s 23ms/step - loss: 0.1078 - accuracy: 0.9529\n",
      "Epoch 180/200\n",
      "1209/1209 [==============================] - 25s 21ms/step - loss: 0.1559 - accuracy: 0.9289\n",
      "Epoch 181/200\n",
      "1209/1209 [==============================] - 20s 17ms/step - loss: 0.1232 - accuracy: 0.9371\n",
      "Epoch 182/200\n",
      "1209/1209 [==============================] - 27s 22ms/step - loss: 0.1272 - accuracy: 0.9330\n",
      "Epoch 183/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1331 - accuracy: 0.9380\n",
      "Epoch 184/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1351 - accuracy: 0.9313\n",
      "Epoch 185/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.1429 - accuracy: 0.9355\n",
      "Epoch 186/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1417 - accuracy: 0.9404\n",
      "Epoch 187/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.1719 - accuracy: 0.9214\n",
      "Epoch 188/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1654 - accuracy: 0.9214\n",
      "Epoch 189/200\n",
      "1209/1209 [==============================] - 20s 16ms/step - loss: 0.1568 - accuracy: 0.9305\n",
      "Epoch 190/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.1258 - accuracy: 0.9438\n",
      "Epoch 191/200\n",
      "1209/1209 [==============================] - 28s 23ms/step - loss: 0.1189 - accuracy: 0.9388\n",
      "Epoch 192/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.1231 - accuracy: 0.9413\n",
      "Epoch 193/200\n",
      "1209/1209 [==============================] - 26s 22ms/step - loss: 0.1270 - accuracy: 0.9454\n",
      "Epoch 194/200\n",
      "1209/1209 [==============================] - 22s 18ms/step - loss: 0.1099 - accuracy: 0.9495\n",
      "Epoch 195/200\n",
      "1209/1209 [==============================] - 16s 13ms/step - loss: 0.1508 - accuracy: 0.9388\n",
      "Epoch 196/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1178 - accuracy: 0.9446\n",
      "Epoch 197/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.1009 - accuracy: 0.9462\n",
      "Epoch 198/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.1325 - accuracy: 0.9355\n",
      "Epoch 199/200\n",
      "1209/1209 [==============================] - 14s 11ms/step - loss: 0.1291 - accuracy: 0.9396\n",
      "Epoch 200/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.1329 - accuracy: 0.9371\n",
      "135/135 [==============================] - 7s 49ms/step\n",
      "---------------------------epoch :  2 ---------------------------\n",
      "Epoch 1/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 1.3737 - accuracy: 0.5219\n",
      "Epoch 2/200\n",
      "1209/1209 [==============================] - 15s 13ms/step - loss: 0.7812 - accuracy: 0.5335\n",
      "Epoch 3/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.6944 - accuracy: 0.5889\n",
      "Epoch 4/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.6790 - accuracy: 0.5732\n",
      "Epoch 5/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.6459 - accuracy: 0.6261\n",
      "Epoch 6/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.6251 - accuracy: 0.6361\n",
      "Epoch 7/200\n",
      "1209/1209 [==============================] - 14s 11ms/step - loss: 0.5956 - accuracy: 0.6642\n",
      "Epoch 8/200\n",
      "1209/1209 [==============================] - 14s 11ms/step - loss: 0.5815 - accuracy: 0.6898\n",
      "Epoch 9/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.5448 - accuracy: 0.7361\n",
      "Epoch 10/200\n",
      "1209/1209 [==============================] - 12s 10ms/step - loss: 0.5406 - accuracy: 0.6998\n",
      "Epoch 11/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.5047 - accuracy: 0.7560\n",
      "Epoch 12/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.5215 - accuracy: 0.7419\n",
      "Epoch 13/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.4432 - accuracy: 0.7849\n",
      "Epoch 14/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.4419 - accuracy: 0.7849\n",
      "Epoch 15/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.4465 - accuracy: 0.7899\n",
      "Epoch 16/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.3944 - accuracy: 0.8213\n",
      "Epoch 17/200\n",
      "1209/1209 [==============================] - 18s 14ms/step - loss: 0.3877 - accuracy: 0.8180\n",
      "Epoch 18/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.3680 - accuracy: 0.8263\n",
      "Epoch 19/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.3549 - accuracy: 0.8453\n",
      "Epoch 20/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.3582 - accuracy: 0.8354\n",
      "Epoch 21/200\n",
      "1209/1209 [==============================] - 12s 10ms/step - loss: 0.3118 - accuracy: 0.8660\n",
      "Epoch 22/200\n",
      "1209/1209 [==============================] - 17s 14ms/step - loss: 0.3038 - accuracy: 0.8569\n",
      "Epoch 23/200\n",
      "1209/1209 [==============================] - 18s 14ms/step - loss: 0.3246 - accuracy: 0.8586\n",
      "Epoch 24/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.2818 - accuracy: 0.8768\n",
      "Epoch 25/200\n",
      "1209/1209 [==============================] - 13s 10ms/step - loss: 0.2822 - accuracy: 0.8883\n",
      "Epoch 26/200\n",
      "1209/1209 [==============================] - 13s 10ms/step - loss: 0.2696 - accuracy: 0.8883\n",
      "Epoch 27/200\n",
      "1209/1209 [==============================] - 13s 11ms/step - loss: 0.2465 - accuracy: 0.8958\n",
      "Epoch 28/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.2667 - accuracy: 0.8768\n",
      "Epoch 29/200\n",
      "1209/1209 [==============================] - 15s 12ms/step - loss: 0.2479 - accuracy: 0.8875\n",
      "Epoch 30/200\n",
      "1209/1209 [==============================] - 14s 12ms/step - loss: 0.2559 - accuracy: 0.8916\n",
      "Epoch 31/200\n",
      "1209/1209 [==============================] - 19s 16ms/step - loss: 0.2165 - accuracy: 0.9090\n",
      "Epoch 32/200\n",
      "1209/1209 [==============================] - 18s 15ms/step - loss: 0.2220 - accuracy: 0.9098\n",
      "Epoch 33/200\n",
      " 580/1209 [=============>................] - ETA: 7s - loss: 0.2307 - accuracy: 0.9000"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "k_accuracy = list()\n",
    "accuracy = list()\n",
    "mat = list()\n",
    "\n",
    "model, weights = create_model()\n",
    "for train, test in kfold.split(x_data):\n",
    "    #cuda.select_device (0)\n",
    "    #model = create_model()\n",
    "    num = num+1\n",
    "    print(\"---------------------------epoch : \",num,\"---------------------------\")\n",
    "    init_weight(model, weights)\n",
    "    model.fit(x_data[train], y_data[train], epochs=200, batch_size=20, callbacks=[es])\n",
    "    accuracy =  (model.evaluate(x_data[test], y_data[test]))\n",
    "    k_accuracy.append(accuracy)\n",
    "    \n",
    "    mat.append(cf_mat(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
